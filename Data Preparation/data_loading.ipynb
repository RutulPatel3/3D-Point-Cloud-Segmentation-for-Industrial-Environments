{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea51b2f",
   "metadata": {},
   "source": [
    "## PROBLEM NEEDS TO BE FIXED\n",
    "\n",
    "--> until SCAN_30 it works properly but after that it mismatches the labels and id with the map file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17342ea8",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5550ffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from plyfile import PlyData, PlyElement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5fc029",
   "metadata": {},
   "source": [
    "# DATA LOADING AND INITIAL VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc037d9",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a42f1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "# IMPORTANT: Adjust these paths to your downloaded EDF dataset location\n",
    "dataset_root_path = 'C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility'\n",
    "\n",
    "# Assuming these file names based on your description\n",
    "global_labels_file = 'ytrain_i9bpfD4.csv' # The big Excel file with all ID-class mappings\n",
    "train_map_file = 'suppfiles_HtLAvex/ytrain_map_ind_station.csv' # Mapping for training stations\n",
    "test_map_file = 'suppfiles_HtLAvex/ytest_map_ind_station.csv'   # Mapping for testing stations\n",
    "\n",
    "# Choose whether to load from 'train' or 'test' set\n",
    "data_split = 'train' # or 'test'\n",
    "\n",
    "# Choose which station ID to visualize (e.g., 0, 1, 31, 32 based on your map files)\n",
    "# If data_split is 'train', choose a station_id from ytrain_map_ind_station.csv\n",
    "# If data_split is 'test', choose a station_id from ytest_map_ind_station.csv\n",
    "station_id_to_visualize = 4 # Example: visualizing SCAN_0.ply from train set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39da3c6",
   "metadata": {},
   "source": [
    "## Defining Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eff7c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Define Paths ---\n",
    "global_labels_path = os.path.join(dataset_root_path, global_labels_file)\n",
    "\n",
    "if data_split == 'train':\n",
    "    map_file_path = os.path.join(dataset_root_path, train_map_file)\n",
    "    ply_folder_path = os.path.join(dataset_root_path, 'xtrain_kW4SLO1') # Assuming 'train' subdir for PLY files\n",
    "elif data_split == 'test':\n",
    "    map_file_path = os.path.join(dataset_root_path, test_map_file)\n",
    "    ply_folder_path = os.path.join(dataset_root_path, 'test') # Assuming 'test' subdir for PLY files\n",
    "else:\n",
    "    raise ValueError(\"data_split must be 'train' or 'test'\")\n",
    "\n",
    "ply_file_name = f'SCAN_{station_id_to_visualize}.ply'\n",
    "ply_file_path = os.path.join(ply_folder_path, ply_file_name)\n",
    "\n",
    "# Define class colors for visualization (you can expand this for all 10 classes)\n",
    "# These are just example colors. You can choose more distinct ones.\n",
    "# Make sure the index matches the label ID (e.g., colors[0] for label 0, colors[1] for label 1)\n",
    "# These are the 10 classes as per EDF dataset documentation (0-9)\n",
    "CLASS_COLORS = {\n",
    "    0: [0.5, 0.5, 0.5],  # Background (grey)\n",
    "    1: [1.0, 0.0, 0.0],  # Beams (red)\n",
    "    2: [0.0, 1.0, 0.0],  # Cabletrays (green)\n",
    "    3: [0.0, 0.0, 1.0],  # Civils (blue - for walls/floors)\n",
    "    4: [1.0, 1.0, 0.0],  # Gratings (yellow)\n",
    "    5: [1.0, 0.5, 0.0],  # Guardrails (orange)\n",
    "    6: [0.0, 1.0, 1.0],  # Hvac (cyan)\n",
    "    7: [0.5, 0.0, 0.5],  # Ladders (purple)\n",
    "    8: [1.0, 0.0, 1.0],  # Pipping (magenta - for pipes!)\n",
    "    9: [0.5, 0.5, 0.0],  # Supports (olive)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422a589",
   "metadata": {},
   "source": [
    "## Loading Global File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd53e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading global labels from: C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility\\ytrain_i9bpfD4.csv\n",
      "Successfully loaded 130661990 global labels. Data type: int64\n",
      "DEBUG: First 5 labels: [8 8 8 8 8]\n",
      "DEBUG: Last 5 labels: [8 8 3 8 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. Load the Global Labels File ---\n",
    "print(f\"Loading global labels from: {global_labels_path}\")\n",
    "try:\n",
    "    # --- FIX HERE: Remove header=None and names=['class'] ---\n",
    "    # Pandas will now correctly read the header row and use 'class' as the column name.\n",
    "    # We still specify dtype for the 'class' column to ensure it's loaded as int64.\n",
    "    global_labels_df = pd.read_csv(global_labels_path, dtype={'class': np.int64})\n",
    "    \n",
    "    # Check if 'class' column exists AFTER reading with header\n",
    "    if 'class' not in global_labels_df.columns:\n",
    "        raise ValueError(\"Global labels CSV must contain a 'class' column after reading its header.\")\n",
    "    \n",
    "    all_labels = global_labels_df['class'].values\n",
    "    \n",
    "    print(f\"Successfully loaded {len(all_labels)} global labels. Data type: {all_labels.dtype}\")\n",
    "    print(f\"DEBUG: First 5 labels: {all_labels[:5]}\")\n",
    "    # Ensure there are enough labels before trying to print last 5\n",
    "    if len(all_labels) > 5:\n",
    "        print(f\"DEBUG: Last 5 labels: {all_labels[-5:]}\")\n",
    "    \n",
    "except MemoryError as e:\n",
    "    print(f\"ERROR: Not enough memory to load '{global_labels_file}' (1.5GB). Try increasing RAM or using a server.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading global labels CSV: {e}. Please check '{global_labels_file}' and its content/format.\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abeb7b",
   "metadata": {},
   "source": [
    "## Loading Map FIle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc8a04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading map file from: C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility\\suppfiles_HtLAvex/ytrain_map_ind_station.csv\n",
      "Found mapping for Station 37: start=93562963, end=95226972\n",
      "DEBUG: Data types in map_df: \n",
      "Station_index    int64\n",
      "index_start      int64\n",
      "index_end        int64\n",
      "dtype: object\n",
      "DEBUG: Map entry for Station 37: start=93562963 (type: <class 'numpy.int64'>), end=95226972 (type: <class 'numpy.int64'>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2. Load the Map File for the chosen split ---\n",
    "print(f\"Loading map file from: {map_file_path}\")\n",
    "try:\n",
    "    map_df = pd.read_csv(map_file_path, header=None, names=['Station_index', 'index_start', 'index_end'],\n",
    "                         dtype={'Station_index': np.int64, 'index_start': np.int64, 'index_end': np.int64})    # Find the row corresponding to our chosen station_id\n",
    "    station_info = map_df[map_df['Station_index'] == station_id_to_visualize]\n",
    "\n",
    "    if station_info.empty:\n",
    "        print(f\"ERROR: Station ID {station_id_to_visualize} not found in map file: {map_file_path}.\")\n",
    "        print(f\"Available IDs in map file: {map_df['Station_index'].tolist()}\")\n",
    "        exit()\n",
    "    index_start = station_info['index_start'].iloc[0]\n",
    "    index_end = station_info['index_end'].iloc[0]\n",
    "    print(f\"Found mapping for Station {station_id_to_visualize}: start={index_start}, end={index_end}\")\n",
    "    print(f\"DEBUG: Data types in map_df: \\n{map_df.dtypes}\")\n",
    "    print(f\"DEBUG: Map entry for Station {station_id_to_visualize}: start={index_start} (type: {type(index_start)}), end={index_end} (type: {type(index_end)})\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading map file or finding station info: {e}\")\n",
    "    print(\"Please check 'map_file_path' and 'station_id_to_visualize'.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5d1dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # --- CRITICAL CHECKS FOR INDEX BOUNDS ---\n",
    "    total_labels_count = len(all_labels)\n",
    "    if index_start < 0:\n",
    "        print(f\"CRITICAL ERROR: 'index_start' ({index_start}) for Station {station_id_to_visualize} is negative.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    if index_end >= total_labels_count:\n",
    "        print(f\"CRITICAL ERROR: 'index_end' ({index_end}) for Station {station_id_to_visualize} is OUT OF BOUNDS of 'all_labels' array (total size: {total_labels_count}).\")\n",
    "        print(\"This is the MOST LIKELY CAUSE of the '0 labels' or mismatch for later scans.\")\n",
    "        print(\"This means the map file has indices that point beyond the actual length of your global labels file.\")\n",
    "        print(\"Please verify the integrity of your map file ('ytrain_map_ind_station.csv') and confirm 'ytrain_i9bpfD4.csv' contains as many rows as 'index_end' suggests.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    if index_end < index_start:\n",
    "        print(f\"CRITICAL ERROR: 'index_end' ({index_end}) is less than 'index_start' ({index_start}) for Station {station_id_to_visualize}. This would result in zero or negative labels.\")\n",
    "        sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading map file or finding station info: {e}. Please check '{map_file_path}' and 'station_id_to_visualize'.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bef844",
   "metadata": {},
   "source": [
    "## Label Extraction for the choosen station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aadd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1664010 labels for Station 37.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. Extract Labels for the Specific Station ---\n",
    "try:\n",
    "    # NumPy slicing is [start:end] where 'end' is exclusive.\n",
    "    # If index_end from CSV is inclusive, then we need index_end + 1.\n",
    "    labels_for_station = all_labels[index_start : index_end + 1]\n",
    "    \n",
    "    if len(labels_for_station) == 0:\n",
    "        print(f\"CRITICAL ERROR: Extracted 0 labels for Station {station_id_to_visualize}. This means the slice {index_start}:{index_end+1} yielded no data.\")\n",
    "        print(\"This could be due to index_start == index_end + 1, or previous index_end out-of-bounds error not caught.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"Extracted {len(labels_for_station)} labels for Station {station_id_to_visualize}.\")\n",
    "except IndexError as e:\n",
    "    print(f\"Index error when slicing global labels: {e}\")\n",
    "    print(f\"This implies that the calculated slice [{index_start}:{index_end+1}] is out of bounds for 'all_labels' (total size: {len(all_labels)}).\")\n",
    "    print(\"This is highly likely the cause of your mismatch or '0 labels' issue for later scans.\")\n",
    "    print(\"Double-check if 'ytrain_i9bpfD4.csv' is fully loaded or if its actual row count matches the expected max 'index_end' from the map file.\")\n",
    "    sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c949b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to load PLY file: C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility\\xtrain_kW4SLO1\\SCAN_37.ply\n",
      "DEBUG: PLY file exists. Size: 25.39 MB\n",
      "Attempting to load PLY with 'plyfile' library for 'SCAN_37.ply' using custom element names...\n",
      "Successfully extracted 1664010 points from 'points' element.\n",
      "Warning: 'rgb' element found but missing 'r', 'g', or 'b' properties.\n",
      "Warning: 'intensity' element found but missing 'i' property.\n",
      "Successfully created Open3D PointCloud object with 1664010 points.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Load the Point Cloud (.ply file) for the specific station ---\n",
    "print(f\"\\nAttempting to load PLY file: {ply_file_path}\")\n",
    "\n",
    "# --- DEBUGGING CHECKS ---\n",
    "if not os.path.exists(ply_file_path):\n",
    "    print(f\"DEBUG: ERROR: PLY file DOES NOT EXIST at the specified path: {ply_file_path}\")\n",
    "    print(\"Please double-check your 'dataset_root_path', 'data_split' folder names (train/test), and 'station_id_to_visualize'.\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    file_size = os.path.getsize(ply_file_path) / (1024 * 1024) # Size in MB\n",
    "    print(f\"DEBUG: PLY file exists. Size: {file_size:.2f} MB\")\n",
    "    if file_size < 0.001: # Very small size, might be genuinely empty or just a header\n",
    "        print(\"DEBUG: WARNING: PLY file size is extremely small. It might be empty or corrupted.\")\n",
    "\n",
    "# --- MODIFIED PLY LOADING SECTION (using plyfile with correct element names) ---\n",
    "try:\n",
    "    print(f\"Attempting to load PLY with 'plyfile' library for '{ply_file_name}' using custom element names...\")\n",
    "    plydata = PlyData.read(ply_file_path)\n",
    "\n",
    "    # Extract points from the 'points' element\n",
    "    if 'points' in plydata:\n",
    "        points_element = plydata['points']\n",
    "        points = np.vstack([points_element['x'], points_element['y'], points_element['z']]).T\n",
    "        print(f\"Successfully extracted {len(points)} points from 'points' element.\")\n",
    "    else:\n",
    "        raise ValueError(\"PLY file does not contain a 'points' element as expected from header.\")\n",
    "\n",
    "    # Extract colors from the 'rgb' element\n",
    "    colors = None\n",
    "    if 'rgb' in plydata:\n",
    "        rgb_element = plydata['rgb']\n",
    "        # Assuming 'r', 'g', 'b' properties exist within 'rgb' element\n",
    "        if 'r' in rgb_element.properties and 'g' in rgb_element.properties and 'b' in rgb_element.properties:\n",
    "            colors = np.vstack([rgb_element['r'], rgb_element['g'], rgb_element['b']]).T\n",
    "            # Normalize colors to [0, 1] if they are 0-255 (uchar)\n",
    "            if colors.max() > 1.0:\n",
    "                colors = colors / 255.0\n",
    "            print(\"Successfully extracted RGB colors from 'rgb' element.\")\n",
    "        else:\n",
    "            print(\"Warning: 'rgb' element found but missing 'r', 'g', or 'b' properties.\")\n",
    "    else:\n",
    "        print(\"No 'rgb' element found in PLY file for colors.\")\n",
    "\n",
    "    # Optionally, extract intensity from the 'intensity' element\n",
    "    intensity = None\n",
    "    if 'intensity' in plydata:\n",
    "        intensity_element = plydata['intensity']\n",
    "        if 'i' in intensity_element.properties:\n",
    "            intensity = intensity_element['i']\n",
    "            print(f\"Successfully extracted {len(intensity)} intensity values from 'intensity' element.\")\n",
    "        else:\n",
    "            print(\"Warning: 'intensity' element found but missing 'i' property.\")\n",
    "    else:\n",
    "        print(\"No 'intensity' element found in PLY file.\")\n",
    "\n",
    "\n",
    "    # Create Open3D PointCloud object\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    if colors is not None:\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    # Note: Open3D does not have a direct 'intensity' property for visualization,\n",
    "    # but you can store it or use it for other processing.\n",
    "\n",
    "    if not pcd.has_points():\n",
    "        raise ValueError(\"PointCloud created from plyfile has no points after conversion.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to load PLY file using 'plyfile' library with custom elements: {e}\")\n",
    "    print(\"This suggests a deeper issue with the PLY file's structure or corruption, or an unexpected header format.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"Successfully created Open3D PointCloud object with {len(pcd.points)} points.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c959b430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying Point Cloud and Label Lengths ---\n",
      "SUCCESS: Point cloud length (1664010) matches label length (1664010).\n",
      "Point cloud colored by semantic labels.\n",
      "\n",
      "Visualizing Station 37 (train split). Close the visualization window to continue.\n",
      "Visualization complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Verify Lengths and Prepare Colors for Visualization ---\n",
    "print(\"\\n--- Verifying Point Cloud and Label Lengths ---\")\n",
    "if len(pcd.points) != len(labels_for_station):\n",
    "    print(f\"\\nCRITICAL ERROR: Mismatch detected! Number of points ({len(pcd.points)}) in '{ply_file_name}' \"\n",
    "          f\"does NOT match number of labels ({len(labels_for_station)}) extracted from global file ({index_start}:{index_end+1}).\")\n",
    "    print(\"This confirms the problem. Check the previous error messages for root cause (likely index out of bounds).\")\n",
    "    print(\"Exiting as segmentation would be incorrect.\")\n",
    "    sys.exit(1) # Exit because the fundamental data integrity is broken\n",
    "else:\n",
    "    print(f\"SUCCESS: Point cloud length ({len(pcd.points)}) matches label length ({len(labels_for_station)}).\")\n",
    "\n",
    "# Create an array to hold the colors based on labels\n",
    "colors_from_labels = np.zeros((len(labels_for_station), 3))\n",
    "for i, label_id in enumerate(labels_for_station):\n",
    "    label_id_int = int(label_id)\n",
    "    colors_from_labels[i] = CLASS_COLORS.get(label_id_int, [0.8, 0.8, 0.8])\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors_from_labels)\n",
    "print(\"Point cloud colored by semantic labels.\")\n",
    "\n",
    "# --- 6. Visualize the Point Cloud ---\n",
    "print(f\"\\nVisualizing Station {station_id_to_visualize} ({data_split} split). Close the visualization window to continue.\")\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "print(\"Visualization complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbe6e4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Exploration Notes ---\n",
      "Number of points loaded for this station: 1971824\n",
      "Label distribution for this station:\n",
      "  Class Background (ID 0): 46419 points\n",
      "  Class Beams (ID 1): 46412 points\n",
      "  Class Cabletrays (ID 2): 699 points\n",
      "  Class Civils (ID 3): 1307478 points\n",
      "  Class Gratings (ID 4): 218876 points\n",
      "  Class Guardrails (ID 5): 98398 points\n",
      "  Class Hvac (ID 6): 2187 points\n",
      "  Class Ladders (ID 7): 221969 points\n",
      "  Class Pipping (ID 8): 22888 points\n",
      "  Class Supports (ID 9): 6498 points\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 7. Initial Exploration Insights ---\n",
    "print(\"\\n--- Initial Exploration Notes ---\")\n",
    "print(f\"Number of points loaded for this station: {len(pcd.points)}\")\n",
    "unique_labels, counts = np.unique(labels_for_station, return_counts=True)\n",
    "print(\"Label distribution for this station:\")\n",
    "label_names_map = {\n",
    "    0: \"Background\", 1: \"Beams\", 2: \"Cabletrays\", 3: \"Civils\", 4: \"Gratings\",\n",
    "    5: \"Guardrails\", 6: \"Hvac\", 7: \"Ladders\", 8: \"Pipping\", 9: \"Supports\"\n",
    "}\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    label_name = label_names_map.get(label, f\"Unknown ({label})\")\n",
    "    print(f\"  Class {label_name} (ID {label}): {count} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f6a15d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point cloud colored by semantic labels.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Verify Lengths and Prepare Colors for Visualization ---\n",
    "if len(pcd.points) != len(labels_for_station):\n",
    "    print(f\"\\nCRITICAL WARNING: Number of points ({len(pcd.points)}) in '{ply_file_name}' \"\n",
    "          f\"does NOT match number of labels ({len(labels_for_station)}) extracted via map file ({index_start}:{index_end+1}).\")\n",
    "    print(\"This is a common issue due to incorrect indexing, PLY file corruption, or mismatched data generation.\")\n",
    "    print(\"For visualization, truncating to the minimum length to avoid errors, but investigate this mismatch.\")\n",
    "    min_len = min(len(pcd.points), len(labels_for_station))\n",
    "    pcd.points = o3d.utility.Vector3dVector(np.asarray(pcd.points)[:min_len])\n",
    "    # Preserve original colors if they exist, otherwise set to dummy for slicing\n",
    "    # Use the colors loaded from PLY, or if not available, default to grey.\n",
    "    if pcd.has_colors():\n",
    "        pcd.colors = o3d.utility.Vector3dVector(np.asarray(pcd.colors)[:min_len])\n",
    "    else:\n",
    "        pcd.colors = o3d.utility.Vector3dVector(np.full((min_len, 3), 0.7)) # Grey if no colors from PLY\n",
    "    labels_for_station = labels_for_station[:min_len]\n",
    "    print(f\"Truncated to {min_len} points/labels for visualization.\")\n",
    "\n",
    "# Create an array to hold the colors based on labels\n",
    "colors_from_labels = np.zeros((len(labels_for_station), 3))\n",
    "for i, label_id in enumerate(labels_for_station):\n",
    "    label_id_int = int(label_id) # Ensure label_id is an integer for dictionary lookup\n",
    "    colors_from_labels[i] = CLASS_COLORS.get(label_id_int, [0.8, 0.8, 0.8]) # Default to light grey for unknown labels\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors_from_labels) # OVERWRITE with semantic colors\n",
    "print(\"Point cloud colored by semantic labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "827746a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizing Station 6 (train split). Close the visualization window to continue.\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "Visualization complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Visualize the Point Cloud ---\n",
    "print(f\"\\nVisualizing Station {station_id_to_visualize} ({data_split} split). Close the visualization window to continue.\")\n",
    "\n",
    "# Optional: Downsample for faster visualization if it's too dense\n",
    "# pcd_downsampled = pcd.voxel_down_sample(voxel_size=0.05) # Adjust voxel_size as needed\n",
    "# o3d.visualization.draw_geometries([pcd_downsampled])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "print(\"Visualization complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8507f56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Exploration Notes ---\n",
      "Number of points loaded for this station: 2920085\n",
      "Label distribution for this station:\n",
      "  Class Background (ID 0): 95715 points\n",
      "  Class Beams (ID 1): 938 points\n",
      "  Class Cabletrays (ID 2): 163731 points\n",
      "  Class Civils (ID 3): 621962 points\n",
      "  Class Gratings (ID 4): 1997 points\n",
      "  Class Guardrails (ID 5): 71797 points\n",
      "  Class Hvac (ID 6): 15866 points\n",
      "  Class Ladders (ID 7): 808 points\n",
      "  Class Pipping (ID 8): 1765894 points\n",
      "  Class Supports (ID 9): 181377 points\n",
      "\n",
      "**Key things to observe during visualization (if successful):**\n",
      "- **Geometric Integrity:** Does the point cloud look complete and well-aligned? Are there obvious holes or misalignments?\n",
      "- **Label Consistency:** Do the colored regions truly correspond to the object types? For example, are all pipes (magenta) connected correctly, and are walls (blue) forming continuous surfaces?\n",
      "- **Boundaries:** How clear are the boundaries between different segmented objects? Are they sharp or blurry?\n",
      "- **Object Sizes & Density:** Observe the varying sizes of objects (e.g., large walls vs. thin pipes) and the point density on different surfaces.\n",
      "- **Occlusions:** Identify areas where objects are hidden behind others. This affects how well algorithms can segment them.\n",
      "- **Noise & Outliers:** Look for isolated points or small clusters far from the main structures, which might be sensor noise.\n",
      "- **Overall Complexity:** Get a feel for the complexity of the industrial scene and the challenges it might pose for segmentation.\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Initial Exploration Insights ---\n",
    "print(\"\\n--- Initial Exploration Notes ---\")\n",
    "print(f\"Number of points loaded for this station: {len(pcd.points)}\")\n",
    "unique_labels, counts = np.unique(labels_for_station, return_counts=True)\n",
    "print(\"Label distribution for this station:\")\n",
    "# Mapping label IDs to names for better readability\n",
    "label_names_map = {\n",
    "    0: \"Background\", 1: \"Beams\", 2: \"Cabletrays\", 3: \"Civils\", 4: \"Gratings\",\n",
    "    5: \"Guardrails\", 6: \"Hvac\", 7: \"Ladders\", 8: \"Pipping\", 9: \"Supports\"\n",
    "}\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    label_name = label_names_map.get(label, f\"Unknown ({label})\")\n",
    "    print(f\"  Class {label_name} (ID {label}): {count} points\")\n",
    "\n",
    "print(\"\\n**Key things to observe during visualization (if successful):**\")\n",
    "print(\"- **Geometric Integrity:** Does the point cloud look complete and well-aligned? Are there obvious holes or misalignments?\")\n",
    "print(\"- **Label Consistency:** Do the colored regions truly correspond to the object types? For example, are all pipes (magenta) connected correctly, and are walls (blue) forming continuous surfaces?\")\n",
    "print(\"- **Boundaries:** How clear are the boundaries between different segmented objects? Are they sharp or blurry?\")\n",
    "print(\"- **Object Sizes & Density:** Observe the varying sizes of objects (e.g., large walls vs. thin pipes) and the point density on different surfaces.\")\n",
    "print(\"- **Occlusions:** Identify areas where objects are hidden behind others. This affects how well algorithms can segment them.\")\n",
    "print(\"- **Noise & Outliers:** Look for isolated points or small clusters far from the main structures, which might be sensor noise.\")\n",
    "print(\"- **Overall Complexity:** Get a feel for the complexity of the industrial scene and the challenges it might pose for segmentation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe5b16",
   "metadata": {},
   "source": [
    "## Inital Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83d7bd",
   "metadata": {},
   "source": [
    "### SCAN0\n",
    "\n",
    "\n",
    "Number of points loaded for this station: 2368290\n",
    "\n",
    "\n",
    "Class Background (ID 0): 61829 points :: GREY\n",
    "\n",
    "Class Beam (ID 1): 0 points :: Red\n",
    "\n",
    "Class Cabletrays (ID 2): 39641 points :: GREEN\n",
    "\n",
    "Class Civils (ID 3): 400446 points :: Blue(walls and floors)\n",
    "\n",
    "Class Gratings (ID 4): 0 points :: Yellow\n",
    "\n",
    "Class Guardrails (ID 5): 1403 points :: Orange\n",
    "\n",
    "Class Hvac (ID 6): 2766 points :: Cyan\n",
    "\n",
    "Class ladders (ID 7): 0 points :: purple\n",
    "\n",
    "Class Pipping (ID 8): 1705937 points :: Magenta for pipes\n",
    "\n",
    "Class Supports (ID 9): 156268 points :: olive\n",
    "\n",
    "\n",
    "    0: [0.5, 0.5, 0.5],  # Background (grey)\n",
    "    1: [1.0, 0.0, 0.0],  # Beams (red)\n",
    "    2: [0.0, 1.0, 0.0],  # Cabletrays (green)\n",
    "    3: [0.0, 0.0, 1.0],  # Civils (blue - for walls/floors)\n",
    "    4: [1.0, 1.0, 0.0],  # Gratings (yellow)\n",
    "    5: [1.0, 0.5, 0.0],  # Guardrails (orange)\n",
    "    6: [0.0, 1.0, 1.0],  # Hvac (cyan)\n",
    "    7: [0.5, 0.0, 0.5],  # Ladders (purple)\n",
    "    8: [1.0, 0.0, 1.0],  # Pipping (magenta - for pipes!)\n",
    "    9: [0.5, 0.5, 0.0],  # Supports (olive)\n",
    "\n",
    "Label distribution for this station:: This is critical!\n",
    "\n",
    "Look at the Class <Name> (ID <ID>): <Count> points for each unique label.\n",
    "\n",
    "Identify Class Imbalance: You will likely see that some classes (e.g., 'Civils', 'Pipping') have many more points than others (e.g., 'Ladders', 'Gratings'). This class imbalance is a common challenge in segmentation and will heavily influence your model training strategy (e.g., requiring weighted loss functions, oversampling rare classes).\n",
    "--> there is huge class imbalance like pipes are almost 1/2 of the total points whereas least are gaurdrails around 1k points\n",
    "\n",
    "Confirm all expected classes are present: Are all 10 classes potentially represented in this scan, or just a subset?\n",
    "\n",
    "--> not all classes have points there are there grating, beam and ladders which are not present\n",
    "\n",
    "\n",
    "Identify Objects by Color: Based on your CLASS_COLORS map, try to visually confirm what each color represents. For SCAN_0.ply, can you clearly distinguish:\n",
    "\n",
    "Magenta (Pipping): Do you see continuous pipe structures?\n",
    "--> they are dense but they are not continous, huge gap are there in between\n",
    "\n",
    "Blue (Civils): Are these mainly walls, floors, or large structural elements?\n",
    "--> Yes, similary, some are desne whereas some are sparse\n",
    "\n",
    "Green (Cabletrays): Can you pick out the cable trays?\n",
    "--> yes, they are less but can be identified and those are dense and get not continous in between \n",
    "Red (Beams): Are there structural beams?\n",
    "--> there is no points for that\n",
    "Other Colors: What about Gratings, Guardrails, HVAC, Ladders, Supports, Background?\n",
    "\n",
    "\n",
    "Boundary Observation: How clean are the boundaries between different colored segments? Are they sharp, or do they bleed into each other?\n",
    "--> there are some overlaps other vise its clean and sharp. magenta and blue are overlapping somewhere and are less overlapped. olive and green are bit overlapping but i guess it should get some overlapped\n",
    "Density & Completeness: Are there areas that are very dense or very sparse? Are there missing sections or large holes?\n",
    "--> There are dense but are missing section \n",
    "\n",
    "Noise/Outliers: Do you see any isolated points floating away from the main structures that appear to be noise?\n",
    "--> yes there are many sections which are far away and does not make any importance \n",
    "\n",
    "The visual is looked like it has been taken from one static Lidar sensor or scanner and then Point cloud was generated. beacause of that from one specific angle it has point cloud but looking from the opposite angle, the point cloud is missing but difficult to know exact which angle. for example a horizontal pipe has a dense( not so dense) point cloud but from opposite angle it has no points, looking like it has half pipe. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275bca13",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f32ae85",
   "metadata": {},
   "source": [
    "### SCAN4\n",
    "\n",
    "Number of points loaded for this station: 1654791\n",
    "\n",
    "Label distribution for this station:\n",
    "\n",
    "  Class Background (ID 0): 47192 points\n",
    "\n",
    "  Class Cabletrays (ID 2): 41596 points\n",
    "\n",
    "  Class Civils (ID 3): 318624 points\n",
    "\n",
    "  Class Guardrails (ID 5): 209 points\n",
    "\n",
    "  Class Hvac (ID 6): 122624 points\n",
    "\n",
    "  Class Pipping (ID 8): 1050997 points\n",
    "\n",
    "  Class Supports (ID 9): 73549 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34209099",
   "metadata": {},
   "source": [
    "### SCAN8\n",
    "Number of points loaded for this station: 3316643\n",
    "\n",
    "Label distribution for this station:\n",
    "\n",
    "  Class Background (ID 0): 820127 points\n",
    "\n",
    "  Class Beams (ID 1): 2 points\n",
    "\n",
    "  Class Cabletrays (ID 2): 3360 points\n",
    "\n",
    "  Class Civils (ID 3): 801096 points\n",
    "\n",
    "  Class Guardrails (ID 5): 179 points\n",
    "\n",
    "  Class Hvac (ID 6): 56750 points\n",
    "\n",
    "  Class Ladders (ID 7): 9 points\n",
    "\n",
    "  Class Pipping (ID 8): 1549845 points\n",
    "\n",
    "  Class Supports (ID 9): 85275 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d3c7c",
   "metadata": {},
   "source": [
    "### SCAN6\n",
    "\n",
    "Number of points loaded for this station: 2920085\n",
    "\n",
    "Label distribution for this station:\n",
    "\n",
    "  Class Background (ID 0): 95715 points\n",
    "\n",
    "  Class Beams (ID 1): 938 points\n",
    "\n",
    "  Class Cabletrays (ID 2): 163731 points\n",
    "\n",
    "  Class Civils (ID 3): 621962 points\n",
    "\n",
    "  Class Gratings (ID 4): 1997 points\n",
    "\n",
    "  Class Guardrails (ID 5): 71797 points\n",
    "\n",
    "  Class Hvac (ID 6): 15866 points\n",
    "\n",
    "  Class Ladders (ID 7): 808 points\n",
    "\n",
    "  Class Pipping (ID 8): 1765894 points\n",
    "\n",
    "  Class Supports (ID 9): 181377 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2783e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "522a30ae",
   "metadata": {},
   "source": [
    "## Checking for the points in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec8d24c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility/suppfiles_HtLAvex\\ytrain_map_ind_station.csv\n",
      "--- Scan Sizes Overview ---\n",
      "Total scans: 50\n",
      "Minimum points in a scan: 1612043\n",
      "Maximum points in a scan: 4132927\n",
      "Average points per scan: 2613239.80\n",
      "Median points per scan: 2656528.5\n",
      "\n",
      "--- Top 5 Smallest Scans ---\n",
      "   Station_index  index_start  index_end  point_count  split\n",
      "0             45    109487941  111099983      1612043  train\n",
      "1              4     10953766   12608556      1654791  train\n",
      "2             37     93562963   95226972      1664010  train\n",
      "3             42    104568399  106424116      1855718  train\n",
      "4             58    143275610  145192546      1916937  train\n",
      "\n",
      "--- Top 5 Largest Scans ---\n",
      "    Station_index  index_start  index_end  point_count  split\n",
      "45             64    160422335  163585348      3163014  train\n",
      "46              8     21074972   24391614      3316643  train\n",
      "47             12     32396605   35738625      3342021  train\n",
      "48              2      4856610    8309083      3452474  train\n",
      "49             61    150420389  154553315      4132927  train\n",
      "\n",
      "--- Example of 'Average' Sized Scans (around median) ---\n",
      "    Station_index  index_start  index_end  point_count  split\n",
      "18              1      2368290    4856609      2488320  train\n",
      "30             62    154553316  157370241      2816926  train\n",
      "33             18     49354416   52210232      2855817  train\n",
      "34             26     71466440   74324805      2858366  train\n",
      "35              6     15309272   18229356      2920085  train\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "Suppfiles_path = 'C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility/suppfiles_HtLAvex' # <<< VERIFY THIS PATH\n",
    "\n",
    "train_map_file = 'ytrain_map_ind_station.csv'\n",
    "test_map_file = 'ytest_map_ind_station.csv'\n",
    "\n",
    "# Load train map\n",
    "train_map_path = os.path.join(Suppfiles_path, train_map_file)\n",
    "print(train_map_path)\n",
    "train_map_df = pd.read_csv(train_map_path, header=None, names=['Station_index', 'index_start', 'index_end'])\n",
    "train_map_df['point_count'] = train_map_df['index_end'] - train_map_df['index_start'] + 1\n",
    "train_map_df['split'] = 'train'\n",
    "\n",
    "# Load test map (if you have the test files available)\n",
    "\"\"\"test_map_path = os.path.join(Suppfiles_path, test_map_file)\n",
    "test_map_df = pd.read_csv(test_map_path, header=None, names=['Station_index', 'index_start', 'index_end'])\n",
    "test_map_df['point_count'] = test_map_df['index_end'] - test_map_df['index_start'] + 1\n",
    "test_map_df['split'] = 'test'\"\"\"\n",
    "\n",
    "# Combine and sort for easy viewing\n",
    "all_scans_df = train_map_df\n",
    "all_scans_df_sorted = all_scans_df.sort_values(by='point_count').reset_index(drop=True)\n",
    "\n",
    "print(\"--- Scan Sizes Overview ---\")\n",
    "print(f\"Total scans: {len(all_scans_df_sorted)}\")\n",
    "print(f\"Minimum points in a scan: {all_scans_df_sorted['point_count'].min()}\")\n",
    "print(f\"Maximum points in a scan: {all_scans_df_sorted['point_count'].max()}\")\n",
    "print(f\"Average points per scan: {all_scans_df_sorted['point_count'].mean():.2f}\")\n",
    "print(f\"Median points per scan: {all_scans_df_sorted['point_count'].median()}\")\n",
    "\n",
    "print(\"\\n--- Top 5 Smallest Scans ---\")\n",
    "print(all_scans_df_sorted.head(5))\n",
    "\n",
    "print(\"\\n--- Top 5 Largest Scans ---\")\n",
    "print(all_scans_df_sorted.tail(5))\n",
    "\n",
    "print(\"\\n--- Example of 'Average' Sized Scans (around median) ---\")\n",
    "median_count = all_scans_df_sorted['point_count'].median()\n",
    "print(all_scans_df_sorted[(all_scans_df_sorted['point_count'] >= median_count * 0.9) &\n",
    "                           (all_scans_df_sorted['point_count'] <= median_count * 1.1)].sample(n=min(5, len(all_scans_df_sorted))).sort_values(by='point_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb38002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([83645062], dtype='int64')\n",
      "85309071    95226972\n",
      "Name: ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "start = global_labels_df[global_labels_df[\"ID\"]==index_start]\n",
    "end = global_labels_df[global_labels_df[\"ID\"]==index_end]\n",
    "print(start.index)\n",
    "print(end[\"ID\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc016e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m labels_for_station_try = all_labels[\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m : \u001b[38;5;28mint\u001b[39m(end.index) + \u001b[32m1\u001b[39m]\n",
      "\u001b[31mTypeError\u001b[39m: int() argument must be a string, a bytes-like object or a real number, not 'Index'"
     ]
    }
   ],
   "source": [
    "labels_for_station_try = all_labels[start.index : end.index + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40a47652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            False\n",
       "1            False\n",
       "2            False\n",
       "3            False\n",
       "4            False\n",
       "             ...  \n",
       "130661985    False\n",
       "130661986    False\n",
       "130661987    False\n",
       "130661988    False\n",
       "130661989    False\n",
       "Name: ID, Length: 130661990, dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_labels_df[\"ID\"]==index_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "157eab14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 3, 3, 9, 9, 3, 3, 8, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_for_station[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a128b5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID  class\n",
      "83645062  93562963      3\n",
      "                ID  class\n",
      "83645063  93562964      3\n",
      "                ID  class\n",
      "83645064  93562965      8\n",
      "                ID  class\n",
      "83645065  93562966      4\n",
      "                ID  class\n",
      "83645066  93562967      7\n",
      "                ID  class\n",
      "83645067  93562968      3\n",
      "                ID  class\n",
      "83645068  93562969      3\n",
      "                ID  class\n",
      "83645069  93562970      8\n",
      "                ID  class\n",
      "83645070  93562971      8\n",
      "                ID  class\n",
      "83645071  93562972      1\n"
     ]
    }
   ],
   "source": [
    "for i in range(93562963,93562973):\n",
    "    print(global_labels_df[global_labels_df[\"ID\"]==i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25590c",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7e845",
   "metadata": {},
   "source": [
    "### 1. Outlier Removal (Essential)\n",
    "Problem Addressed: \"Many sections which are far away and does not make any importance\" (noise/outliers).\n",
    "\n",
    "Method:\n",
    "\n",
    "Statistical Outlier Removal (SOR): This is often the first step. It computes the average distance to k-nearest neighbors for each point. Points whose average distance is outside a certain standard deviation are removed.\n",
    "\n",
    "Radius Outlier Removal: Removes points that have fewer than a specified number of neighbors within a given radius.\n",
    "\n",
    "Why: Cleaning noise improves the quality of the point cloud, reduces irrelevant data, and can prevent the model from learning from spurious points.\n",
    "\n",
    "### 2. Normalization & Centering (Standard Practice)\n",
    "Problem Addressed: Preparing data for neural networks, which prefer inputs within a specific range.\n",
    "\n",
    "Method:\n",
    "\n",
    "Global Normalization: Translate all points so the centroid of the entire scene (or a bounding box center) is at the origin (0,0,0). Then, scale the points so they fit within a unit sphere or unit cube (e.g., [-1, 1] for each coordinate).\n",
    "\n",
    "Why: Ensures consistency across different scans (which might have different absolute coordinates) and helps stabilize model training.\n",
    "\n",
    "### 3. Downsampling (Crucial for Performance & Uniformity)\n",
    "Problem Addressed:\n",
    "\n",
    "Large number of points per scan (up to 3.3 million for SCAN8).\n",
    "\n",
    "Potential for varying density (though you noted it's mostly consistent, downsampling can enforce uniformity).\n",
    "\n",
    "Memory management for model training and web visualization.\n",
    "\n",
    "Method:\n",
    "\n",
    "Voxel Grid Downsampling: This is highly recommended. It divides the 3D space into a grid of voxels and, for each voxel, replaces all points within it with a single representative point (e.g., the centroid of the points in that voxel).\n",
    "\n",
    "Why: Reduces the number of points while preserving the overall geometry and structure. It also creates a more uniform point density, which can benefit some point-based neural networks. You'll likely need different voxel sizes for training (e.g., 0.02m-0.05m) vs. web visualization (e.g., 0.1m-0.2m) to balance detail and performance.\n",
    "\n",
    "### 4. Handling Class Imbalance (Critical for Model Performance)\n",
    "Problem Addressed: Pipping and Civils dominate, while Guardrails, Hvac, Ladders, etc., are rare or absent in some scans. Model will be biased towards majority classes.\n",
    "\n",
    "Method (for Training Data):\n",
    "\n",
    "Weighted Cross-Entropy Loss: Assign higher weights to the loss contributions from minority classes during training. This makes the model \"care more\" about correctly classifying rare objects.\n",
    "\n",
    "Oversampling Minority Classes: During data loading for training, you can oversample points belonging to rare classes (e.g., by duplicating them or using techniques like SMOTE for point clouds, though that's more complex).\n",
    "\n",
    "Undersampling Majority Classes: Less common for point clouds due to information loss, but an option if memory is extremely constrained.\n",
    "\n",
    "Class Grouping (Conditional): For classes that are always zero or extremely rare across all scans (e.g., Beams, Gratings, Ladders if they remain consistently absent or negligible), consider if they should be merged into a broader \"Other Structural\" or even \"Background\" class. However, since the dataset defines them, it's better to try to segment them if they appear in any scan.\n",
    "\n",
    "Why: Prevents the model from simply predicting the majority class all the time and ensures it learns to distinguish rare but important components.\n",
    "\n",
    "### 5. Data Augmentation (Essential for Robustness & Generalization)\n",
    "Problem Addressed:\n",
    "\n",
    "Static scanner limitations (\"half-pipe\" effect, missing views).\n",
    "\n",
    "Improving model generalization to unseen variations in industrial scenes.\n",
    "\n",
    "Method (Applied during Training):\n",
    "\n",
    "Random Rotation: Rotate the point cloud around the Z-axis (up-axis) randomly. This helps the model learn features invariant to orientation.\n",
    "\n",
    "Random Scaling: Slightly scale the point cloud.\n",
    "\n",
    "Random Jittering: Add small random noise to point coordinates.\n",
    "\n",
    "Random Dropout: Randomly remove a small percentage of points.\n",
    "\n",
    "Why: Simulates variations in scanning conditions and object poses, making the model more robust and less prone to overfitting to specific scanner viewpoints or incomplete data. This can implicitly help the model learn to \"fill in\" missing parts better.\n",
    "\n",
    "### 6. Feature Engineering (Optional but Potentially Powerful)\n",
    "Problem Addressed: Providing the model with richer information beyond just XYZ coordinates.\n",
    "\n",
    "Method:\n",
    "\n",
    "Compute Normals: Estimate the surface normal vector for each point.\n",
    "\n",
    "Estimate Curvature: Calculate local curvature (e.g., principal curvatures).\n",
    "\n",
    "Local Density: Provide information about how dense the points are in a local neighborhood.\n",
    "\n",
    "Why: Geometric features like normals and curvature are highly discriminative for shapes (e.g., pipes have high curvature in one direction, walls are flat). This can significantly boost segmentation accuracy, especially for thin structures.\n",
    "\n",
    "Considerations for Model Selection (Re-emphasized):\n",
    "Large-Scale Models: Given the point counts (millions per scan), you'll need models designed for large-scale point clouds, such as RandLA-Net or sparse convolutional networks (e.g., those using MinkowskiEngine). PointNet++ might be too slow or memory-intensive for direct application on full scans without aggressive downsampling or a hierarchical approach.\n",
    "\n",
    "Robustness to Sparsity/Occlusion: The chosen model should ideally have mechanisms to handle varying point densities and occlusions. Local feature aggregation and contextual learning are important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796ce45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f16d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "006c195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading Function (Reused from previous successful script) ---\n",
    "def load_station_data(station_id, ply_folder_path, dataset_root_path, global_labels_path, map_file_path):\n",
    "    \"\"\"\n",
    "    Loads point cloud and corresponding labels for a given station ID and data split.\n",
    "    \"\"\"\n",
    "    ply_file_name = f'SCAN_{station_id}.ply'\n",
    "    ply_file_path = os.path.join(ply_folder_path, ply_file_name)\n",
    "\n",
    "    # Load global labels (assuming already loaded once for efficiency if called repeatedly)\n",
    "    # For this function, we'll load it each time for self-containment, but in a full pipeline,\n",
    "    # you'd load all_labels once at the start.\n",
    "    try:\n",
    "        global_labels_df = pd.read_csv(global_labels_path, dtype={'class': np.int64})\n",
    "        all_labels = global_labels_df['class'].values\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading global labels CSV: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Load map file\n",
    "    try:\n",
    "        map_df = pd.read_csv(map_file_path, header=None, names=['Station_index', 'index_start', 'index_end'],\n",
    "                             dtype={'Station_index': np.int64, 'index_start': np.int64, 'index_end': np.int64})\n",
    "        station_info = map_df[map_df['Station_index'] == station_id]\n",
    "        if station_info.empty:\n",
    "            print(f\"Station ID {station_id} not found in map file: {map_file_path}\")\n",
    "            return None, None\n",
    "        index_start = station_info['index_start'].iloc[0]\n",
    "        index_end = station_info['index_end'].iloc[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading map file or finding station info: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Extract labels for the specific station\n",
    "    total_labels_count = len(all_labels)\n",
    "    if index_end >= total_labels_count or index_start < 0 or index_end < index_start:\n",
    "        print(f\"Label index out of bounds or invalid for Station {station_id}: [{index_start}:{index_end+1}] \"\n",
    "              f\"vs total labels {total_labels_count}. Skipping.\")\n",
    "        return None, None\n",
    "    labels_for_station = all_labels[index_start : index_end + 1]\n",
    "\n",
    "    # Load PLY data using plyfile\n",
    "    try:\n",
    "        plydata = PlyData.read(ply_file_path)\n",
    "        points_element = plydata['points']\n",
    "        points = np.vstack([points_element['x'], points_element['y'], points_element['z']]).T\n",
    "\n",
    "        colors = None\n",
    "        if 'rgb' in plydata:\n",
    "            rgb_element = plydata['rgb']\n",
    "            if 'r' in rgb_element.properties and 'g' in rgb_element.properties and 'b' in rgb_element.properties:\n",
    "                colors = np.vstack([rgb_element['r'], rgb_element['g'], rgb_element['b']]).T\n",
    "                if colors.max() > 1.0:\n",
    "                    colors = colors / 255.0\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        if colors is not None:\n",
    "            pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        if not pcd.has_points():\n",
    "            print(f\"PLY file '{ply_file_name}' loaded but contains no points.\")\n",
    "            return None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PLY file '{ply_file_name}': {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Final length check\n",
    "    if len(pcd.points) != len(labels_for_station):\n",
    "        print(f\"Mismatch: Points ({len(pcd.points)}) != Labels ({len(labels_for_station)}) for Station {station_id}. Skipping.\")\n",
    "        return None, None\n",
    "\n",
    "    return pcd, labels_for_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0bb492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocessing Functions ---\n",
    "\n",
    "def remove_outliers(pcd, nb_neighbors=20, std_ratio=2.0, display_result=False):\n",
    "    \"\"\"\n",
    "    Removes statistical outliers from the point cloud.\n",
    "    :param pcd: Open3D PointCloud object.\n",
    "    :param nb_neighbors: Number of neighbors to consider for each point.\n",
    "    :param std_ratio: Standard deviation ratio.\n",
    "    :param display_result: If True, visualize the point cloud after outlier removal.\n",
    "    :return: Cleaned Open3D PointCloud object.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Outlier Removal (Statistical) ---\")\n",
    "    print(f\"Original points: {len(pcd.points)}\")\n",
    "    cl, ind = pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "    inlier_pcd = pcd.select_by_index(ind)\n",
    "    outlier_pcd = pcd.select_by_index(ind, invert=True) # Optional: visualize outliers\n",
    "    print(f\"Points after outlier removal: {len(inlier_pcd.points)}\")\n",
    "    print(f\"Removed {len(outlier_pcd.points)} outliers.\")\n",
    "\n",
    "    if display_result:\n",
    "        # Color outliers red for visualization\n",
    "        outlier_pcd.paint_uniform_color([1, 0, 0])\n",
    "        # Color inliers green for visualization\n",
    "        # inlier_pcd.paint_uniform_color([0, 1, 0]) # Commented out to preserve semantic colors later\n",
    "        print(\"Visualizing inliers (original color) and outliers (red). Close window to continue.\")\n",
    "        o3d.visualization.draw_geometries([inlier_pcd, outlier_pcd])\n",
    "    \n",
    "    return inlier_pcd, ind # Return inlier indices to filter labels as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e31965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_center(pcd, display_result=False):\n",
    "    \"\"\"\n",
    "    Centers the point cloud and scales it to fit within a unit sphere.\n",
    "    :param pcd: Open3D PointCloud object.\n",
    "    :param display_result: If True, visualize the normalized point cloud.\n",
    "    :return: Normalized Open3D PointCloud object.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Normalization and Centering ---\")\n",
    "    # Get points as NumPy array\n",
    "    points = np.asarray(pcd.points)\n",
    "\n",
    "    # 1. Center the point cloud\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    points_centered = points - centroid\n",
    "    print(f\"Centered point cloud by moving centroid to origin: {centroid}\")\n",
    "\n",
    "    # 2. Scale to unit sphere\n",
    "    # Find the maximum distance from the origin\n",
    "    max_distance = np.max(np.linalg.norm(points_centered, axis=1))\n",
    "    if max_distance > 0:\n",
    "        points_normalized = points_centered / max_distance\n",
    "        print(f\"Scaled point cloud to fit within unit sphere (max distance: {max_distance:.4f})\")\n",
    "    else:\n",
    "        points_normalized = points_centered # Already at origin, no scaling needed\n",
    "        print(\"Point cloud is a single point or empty, no scaling performed.\")\n",
    "\n",
    "    # Update the point cloud object\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_normalized)\n",
    "\n",
    "    if display_result:\n",
    "        print(\"Visualizing normalized and centered point cloud. Close window to continue.\")\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "632426b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_voxel_grid(pcd, voxel_size=0.05, display_result=False):\n",
    "    \"\"\"\n",
    "    Downsamples the point cloud using a voxel grid.\n",
    "    :param pcd: Open3D PointCloud object.\n",
    "    :param voxel_size: Size of the voxel. Larger size means more aggressive downsampling.\n",
    "                       Typical values: 0.01m to 0.1m for industrial scenes.\n",
    "    :param display_result: If True, visualize the downsampled point cloud.\n",
    "    :return: Downsampled Open3D PointCloud object.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Voxel Grid Downsampling ---\")\n",
    "    print(f\"Original points: {len(pcd.points)}\")\n",
    "    downsampled_pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "    print(f\"Points after downsampling (voxel size {voxel_size}m): {len(downsampled_pcd.points)}\")\n",
    "\n",
    "    if display_result:\n",
    "        print(\"Visualizing downsampled point cloud. Close window to continue.\")\n",
    "        o3d.visualization.draw_geometries([downsampled_pcd])\n",
    "    \n",
    "    return downsampled_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d0481ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normals(pcd, radius=0.1, max_nn=30, display_result=False):\n",
    "    \"\"\"\n",
    "    Estimates surface normals for each point.\n",
    "    :param pcd: Open3D PointCloud object.\n",
    "    :param radius: Search radius for neighbors.\n",
    "    :param max_nn: Maximum number of neighbors to consider.\n",
    "    :param display_result: If True, visualize point cloud with normals.\n",
    "    :return: PointCloud object with normals.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Computing Normals ---\")\n",
    "    # Ensure point cloud has a KDTree for neighbor search\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius, max_nn=max_nn))\n",
    "    # Orient normals consistently (optional but good practice)\n",
    "    pcd.orient_normals_to_align_with_direction(orientation_reference=np.array([0., 0., 1.])) # Align with Z-axis\n",
    "    print(f\"Normals computed for {len(pcd.points)} points.\")\n",
    "\n",
    "    if display_result:\n",
    "        print(\"Visualizing point cloud with normals. Close window to continue.\")\n",
    "        # Normals are visualized as small lines extending from points\n",
    "        o3d.visualization.draw_geometries([pcd], point_show_normal=True)\n",
    "    \n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c240e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(points, labels, rotation_range=(-np.pi/12, np.pi/12), scale_range=(0.8, 1.2), jitter_std=0.01):\n",
    "    \"\"\"\n",
    "    Applies random rotation, scaling, and jittering to point cloud data.\n",
    "    This function should be used ONLY for TRAINING DATA.\n",
    "    :param points: NumPy array of shape (N, 3) for XYZ coordinates.\n",
    "    :param labels: NumPy array of shape (N,) for class labels.\n",
    "    :param rotation_range: Tuple (min_angle, max_angle) in radians for Z-axis rotation.\n",
    "    :param scale_range: Tuple (min_scale, max_scale) for uniform scaling.\n",
    "    :param jitter_std: Standard deviation for Gaussian noise jittering.\n",
    "    :return: Augmented points and labels.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Applying Data Augmentation ---\")\n",
    "    \n",
    "    # 1. Random Rotation (around Z-axis)\n",
    "    angle = np.random.uniform(rotation_range[0], rotation_range[1])\n",
    "    cosval = np.cos(angle)\n",
    "    sinval = np.sin(angle)\n",
    "    rotation_matrix = np.array([[cosval, -sinval, 0],\n",
    "                                [sinval, cosval, 0],\n",
    "                                [0, 0, 1]])\n",
    "    points = np.dot(points.reshape(-1, 3), rotation_matrix)\n",
    "\n",
    "    # 2. Random Scaling\n",
    "    scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    points = points * scale\n",
    "\n",
    "    # 3. Random Jittering\n",
    "    jitter = np.random.normal(0, jitter_std, points.shape)\n",
    "    points = points + jitter\n",
    "\n",
    "    print(\"Applied random rotation, scaling, and jittering.\")\n",
    "    return points, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8f52b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Preprocessing Demo for Station 4  ---\n",
      "\n",
      "--- Raw Data Loaded ---\n",
      "Points: 1654791, Labels: 1654791\n",
      "Visualizing raw data with semantic colors. Close window to continue.\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution Flow for Preprocessing Demonstration ---\n",
    "\n",
    "print(f\"--- Starting Preprocessing Demo for Station {station_id_to_visualize}  ---\")\n",
    "\n",
    "# 1. Load the raw point cloud and labels\n",
    "pcd_raw, labels_raw = load_station_data(station_id_to_visualize, ply_folder_path,\n",
    "                                        dataset_root_path, global_labels_path, map_file_path)\n",
    "\n",
    "if pcd_raw is None:\n",
    "    print(\"Failed to load initial data. Exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"\\n--- Raw Data Loaded ---\")\n",
    "print(f\"Points: {len(pcd_raw.points)}, Labels: {len(labels_raw)}\")\n",
    "\n",
    "# Apply semantic colors for initial visualization\n",
    "colors_initial = np.zeros((len(labels_raw), 3))\n",
    "for i, label_id in enumerate(labels_raw):\n",
    "    colors_initial[i] = CLASS_COLORS.get(int(label_id), [0.8, 0.8, 0.8])\n",
    "pcd_raw.colors = o3d.utility.Vector3dVector(colors_initial)\n",
    "\n",
    "print(\"Visualizing raw data with semantic colors. Close window to continue.\")\n",
    "o3d.visualization.draw_geometries([pcd_raw])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08965f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3463bc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Outlier Removal (Statistical) ---\n",
      "Original points: 1654791\n",
      "Points after outlier removal: 1623601\n",
      "Removed 31190 outliers.\n",
      "Visualizing inliers (original color) and outliers (red). Close window to continue.\n"
     ]
    }
   ],
   "source": [
    "# 2. Outlier Removal\n",
    "pcd_cleaned, inlier_indices = remove_outliers(pcd_raw, nb_neighbors=30, std_ratio=2.0, display_result=True)\n",
    "# Filter labels to match the cleaned point cloud\n",
    "labels_cleaned = labels_raw[inlier_indices]\n",
    "\n",
    "# Re-apply semantic colors to the cleaned PCD for subsequent steps\n",
    "colors_cleaned = np.zeros((len(labels_cleaned), 3))\n",
    "for i, label_id in enumerate(labels_cleaned):\n",
    "    colors_cleaned[i] = CLASS_COLORS.get(int(label_id), [0.8, 0.8, 0.8])\n",
    "pcd_cleaned.colors = o3d.utility.Vector3dVector(colors_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6bf25c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Normalization and Centering ---\n",
      "Centered point cloud by moving centroid to origin: [ 19838.9410635    1786.32816424 152488.63598938]\n",
      "Scaled point cloud to fit within unit sphere (max distance: 10341.9251)\n",
      "Visualizing normalized and centered point cloud. Close window to continue.\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n"
     ]
    }
   ],
   "source": [
    "# 3. Normalization and Centering\n",
    "pcd_normalized = normalize_and_center(pcd_cleaned, display_result=True)\n",
    "# Note: Normalization only changes coordinates, not point count or labels.\n",
    "# The labels_cleaned array is still valid for pcd_normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0b362d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Voxel Grid Downsampling ---\n",
      "Original points: 1623601\n",
      "Points after downsampling (voxel size 0.03m): 1121\n",
      "Visualizing downsampled point cloud. Close window to continue.\n",
      "\n",
      "Note: Labels are not directly re-associated with downsampled points in this demo for simplicity.\n",
      "In a full training pipeline, ensure labels are correctly propagated during downsampling.\n"
     ]
    }
   ],
   "source": [
    "# 4. Downsampling (for training, you might choose a smaller voxel_size)\n",
    "# For visualization, a slightly larger voxel_size can make it faster.\n",
    "pcd_downsampled = downsample_voxel_grid(pcd_normalized, voxel_size=0.03, display_result=True)\n",
    "# Downsampling changes point count, so need to re-map labels if you want to use them\n",
    "# This is more complex than simple slicing. For now, we'll just show the downsampled geometry.\n",
    "# In a real training pipeline, you'd ensure labels are correctly associated with downsampled points.\n",
    "# Open3D's voxel_down_sample can return indices, but mapping labels is non-trivial for all methods.\n",
    "# For a deep learning pipeline, you'd typically apply downsampling *before* you extract features/labels for batches.\n",
    "\n",
    "# For demonstration, let's just visualize the downsampled point cloud without labels\n",
    "# If you want labels on downsampled points, you need to ensure the downsampling method preserves label correspondence.\n",
    "# For voxel_down_sample, the centroid of a voxel gets the label of the majority point in that voxel, or one point's label.\n",
    "# This is often handled within the dataset loading for the ML framework.\n",
    "print(f\"\\nNote: Labels are not directly re-associated with downsampled points in this demo for simplicity.\")\n",
    "print(f\"In a full training pipeline, ensure labels are correctly propagated during downsampling.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "680e7363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Computing Normals ---\n",
      "Normals computed for 1121 points.\n",
      "Visualizing point cloud with normals. Close window to continue.\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "\n",
      "--- Demonstrating Data Augmentation (for Training Data Only) ---\n",
      "This step is applied on the NumPy arrays of points and labels during training.\n"
     ]
    }
   ],
   "source": [
    "# 5. Compute Normals (added as a feature)\n",
    "# This is often done after downsampling if you want normals for the downsampled points.\n",
    "pcd_with_normals = compute_normals(pcd_downsampled, radius=0.1, max_nn=30, display_result=True)\n",
    "# Normals are stored as a property of the PCD object and would be passed to the model.\n",
    "\n",
    "# --- Data Augmentation Demonstration (ONLY for training data) ---\n",
    "print(\"\\n--- Demonstrating Data Augmentation (for Training Data Only) ---\")\n",
    "print(\"This step is applied on the NumPy arrays of points and labels during training.\")\n",
    "\n",
    "# Get points and labels as NumPy arrays from the *cleaned* data for augmentation demo\n",
    "# (or from the downsampled data if your model expects augmented downsampled points)\n",
    "points_for_augmentation = np.asarray(pcd_cleaned.points)\n",
    "labels_for_augmentation = labels_cleaned.copy() # Make a copy to avoid modifying original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c83d859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying Data Augmentation ---\n",
      "Applied random rotation, scaling, and jittering.\n",
      "Visualizing augmented point cloud. Close window to continue.\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "\n",
      "--- Preprocessing Demo Complete ---\n",
      "Remember to integrate these steps into your full data loading pipeline for training and inference.\n",
      "Class imbalance handling (weighted loss, sampling) will be part of your model's training loop.\n"
     ]
    }
   ],
   "source": [
    "# Apply augmentation\n",
    "points_augmented, labels_augmented = augment_data(\n",
    "    points_for_augmentation, labels_for_augmentation,\n",
    "    rotation_range=(-np.pi/12, np.pi/12), # +/- 15 degrees\n",
    "    scale_range=(0.9, 1.1),             # +/- 10% scale\n",
    "    jitter_std=0.005                    # Small jitter\n",
    ")\n",
    "\n",
    "# Visualize augmented data (optional, for verification)\n",
    "pcd_augmented = o3d.geometry.PointCloud()\n",
    "pcd_augmented.points = o3d.utility.Vector3dVector(points_augmented)\n",
    "\n",
    "# Re-apply semantic colors to augmented PCD\n",
    "colors_augmented = np.zeros((len(labels_augmented), 3))\n",
    "for i, label_id in enumerate(labels_augmented):\n",
    "    colors_augmented[i] = CLASS_COLORS.get(int(label_id), [0.8, 0.8, 0.8])\n",
    "pcd_augmented.colors = o3d.utility.Vector3dVector(colors_augmented)\n",
    "\n",
    "print(\"Visualizing augmented point cloud. Close window to continue.\")\n",
    "o3d.visualization.draw_geometries([pcd_augmented])\n",
    "\n",
    "print(\"\\n--- Preprocessing Demo Complete ---\")\n",
    "print(\"Remember to integrate these steps into your full data loading pipeline for training and inference.\")\n",
    "print(\"Class imbalance handling (weighted loss, sampling) will be part of your model's training loop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021a39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "351d177c",
   "metadata": {},
   "source": [
    "# Next Steps: Model Development & Training\n",
    "## 1. Prepare Data for Model Input (Custom Dataset & DataLoader)\n",
    "Your preprocessing functions are great, but a deep learning model needs data in a specific, batch-friendly format.\n",
    "\n",
    "Create a Custom Dataset Class (e.g., EDFPointCloudDataset):\n",
    "\n",
    "This class will inherit from PyTorch's torch.utils.data.Dataset (or TensorFlow's equivalent).\n",
    "\n",
    "Its __init__ method will:\n",
    "\n",
    "Load the ytrain_map_ind_station.csv (and ytest_map_ind_station.csv) to get the list of station IDs and their index ranges.\n",
    "\n",
    "Load the ytrain_i9bpfD4.csv (global labels) once into memory.\n",
    "\n",
    "Its __len__ method will return the total number of individual points or (more practically for large scans) the total number of patches if you're processing in patches.\n",
    "\n",
    "Its __getitem__(self, idx) method is the most important:\n",
    "\n",
    "Given an idx, it will determine which SCAN_X.ply file and corresponding label segment to load.\n",
    "\n",
    "It will load the raw point cloud and labels using your load_station_data function.\n",
    "\n",
    "It will apply the chosen preprocessing steps (outlier removal, normalization, optional downsampling, normal computation).\n",
    "\n",
    "Crucially, for training data, it will apply Data Augmentation.\n",
    "\n",
    "It will return the processed points (and optionally normals, colors) and their corresponding labels as NumPy arrays or PyTorch/TensorFlow tensors.\n",
    "\n",
    "Handling Large Scans / Patching: For very large scans (like SCAN_8 with 3.3 million points), you often don't feed the entire scan to the GPU at once. Instead, you extract smaller, overlapping \"patches\" or \"blocks\" from the scan. Your __getitem__ would then return a patch, and its corresponding labels. This is a common strategy for large point cloud datasets.\n",
    "\n",
    "Create a DataLoader (e.g., torch.utils.data.DataLoader):\n",
    "\n",
    "This will wrap your custom dataset.\n",
    "\n",
    "It handles batching (grouping multiple processed point clouds/patches together).\n",
    "\n",
    "It handles shuffling (randomizing the order of samples for training).\n",
    "\n",
    "It handles multiprocessing (loading data in parallel to keep the GPU busy).\n",
    "\n",
    "## 2. Choose a 3D Segmentation Model Architecture\n",
    "Based on your observations (large-scale data, class imbalance, complex industrial environment, missing sections/occlusions), here are the recommended model types:\n",
    "\n",
    "Primary Recommendation: RandLA-Net\n",
    "\n",
    "Why: It's designed for efficiency on large-scale point clouds by using random sampling and local feature aggregation. This directly addresses your large point counts and helps with varying densities. It's a strong candidate for industrial scenes.\n",
    "\n",
    "Resources: You can find PyTorch or TensorFlow implementations on GitHub (e.g., QingyongHu/RandLA-Net).\n",
    "\n",
    "Alternative/Advanced: Sparse Convolutional Networks (e.g., MinkowskiEngine-based)\n",
    "\n",
    "Why: These models operate on sparse voxelized representations, which are very memory-efficient and can be highly accurate for detailed scenes. They are excellent for capturing fine structures like pipes.\n",
    "\n",
    "Complexity: Can be more complex to set up than PointNet-like architectures.\n",
    "\n",
    "Resources: StanfordVL/MinkowskiEngine.\n",
    "\n",
    "Baseline (if others are too complex initially): PointNet++\n",
    "\n",
    "Why: A foundational model that introduced hierarchical feature learning. It's good for understanding the basics.\n",
    "\n",
    "Limitations: Might struggle with very large point clouds without significant downsampling or complex patching strategies.\n",
    "\n",
    "Resources: charlesq34/pointnet2 (TensorFlow), many PyTorch re-implementations.\n",
    "\n",
    "## 3. Implement the Model\n",
    "Once you choose an architecture, you'll implement it using your chosen deep learning framework (PyTorch or TensorFlow).\n",
    "\n",
    "Define the Network: Create the neural network layers (e.g., convolutional layers, pooling layers, fully connected layers) as specified by the chosen architecture.\n",
    "\n",
    "Input Features: Your model will take as input:\n",
    "\n",
    "XYZ coordinates (normalized).\n",
    "\n",
    "Optionally, RGB colors (normalized).\n",
    "\n",
    "Optionally, Intensity (normalized, if you decide to use it).\n",
    "\n",
    "Optionally, Normals (computed in preprocessing).\n",
    "\n",
    "Optionally, other engineered features (e.g., local density).\n",
    "\n",
    "Output: The model will output a prediction for each point, typically a logit or probability score for each of your 10 semantic classes.\n",
    "\n",
    "## 4. Define Loss Function and Optimizer\n",
    "Loss Function:\n",
    "\n",
    "Weighted Cross-Entropy Loss: This is CRITICAL for addressing the severe class imbalance you observed. You'll assign higher weights to the minority classes (e.g., Guardrails, Ladders, Beams) and lower weights to the majority classes (Pipping, Civils). This forces the model to pay more attention to correctly classifying the rare but important objects.\n",
    "\n",
    "How to calculate weights: Weights are typically inversely proportional to the class frequency. You'll need to calculate the point counts for all classes across your entire training dataset to get accurate weights.\n",
    "\n",
    "Optimizer:\n",
    "\n",
    "Adam or AdamW: Common and effective optimizers for deep learning.\n",
    "\n",
    "## 5. Set Up the Training Loop\n",
    "This is the core iterative process where the model learns.\n",
    "\n",
    "Epochs: Number of times the model sees the entire training dataset.\n",
    "\n",
    "Batch Size: Number of point clouds/patches processed at once by the GPU.\n",
    "\n",
    "Learning Rate Scheduler: Adjusts the learning rate during training (e.g., reduce on plateau, cosine annealing) to improve convergence.\n",
    "\n",
    "Forward Pass: Feed batches of input data through the model to get predictions.\n",
    "\n",
    "Loss Calculation: Compute the weighted cross-entropy loss between predictions and ground truth labels.\n",
    "\n",
    "Backward Pass & Optimization: Compute gradients and update model weights.\n",
    "\n",
    "Validation: Periodically (e.g., every few epochs), evaluate the model on a separate validation set to monitor performance and prevent overfitting.\n",
    "\n",
    "Model Checkpointing: Save the model weights (and optimizer state) at regular intervals or when validation performance improves.\n",
    "\n",
    "## 6. Evaluation Metrics\n",
    "Beyond visual inspection, you need quantitative metrics to assess your model's performance.\n",
    "\n",
    "Intersection over Union (IoU) / Jaccard Index:\n",
    "\n",
    "Calculated per class: (True Positives) / (True Positives + False Positives + False Negatives).\n",
    "\n",
    "Mean IoU (mIoU): The average IoU across all classes. This is the primary metric for semantic segmentation.\n",
    "\n",
    "Why: Directly measures the overlap between predicted and ground truth segments.\n",
    "\n",
    "Overall Accuracy: (Total Correctly Classified Points) / (Total Points).\n",
    "\n",
    "Caution: Can be misleading with high class imbalance (a model predicting only 'Pipping' and 'Civils' could still have high overall accuracy).\n",
    "\n",
    "F1-Score (per class): Harmonic mean of precision and recall. Useful for understanding performance on individual classes, especially minority ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bed625",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
