{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17342ea8",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5550ffea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'open3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopen3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mo3d\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'open3d'"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from plyfile import PlyData, PlyElement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc037d9",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42f1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "# IMPORTANT: Adjust these paths to your downloaded EDF dataset location\n",
    "dataset_root_path = 'C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility'\n",
    "\n",
    "# Assuming these file names based on your description\n",
    "global_labels_file = 'ytrain_i9bpfD4.csv' # The big Excel file with all ID-class mappings\n",
    "train_map_file = 'suppfiles_HtLAvex/ytrain_map_ind_station.csv' # Mapping for training stations\n",
    "test_map_file = 'suppfiles_HtLAvex/ytest_map_ind_station.csv'   # Mapping for testing stations\n",
    "\n",
    "# Choose whether to load from 'train' or 'test' set\n",
    "data_split = 'train' # or 'test'\n",
    "\n",
    "# Choose which station ID to visualize (e.g., 0, 1, 31, 32 based on your map files)\n",
    "# If data_split is 'train', choose a station_id from ytrain_map_ind_station.csv\n",
    "# If data_split is 'test', choose a station_id from ytest_map_ind_station.csv\n",
    "station_id_to_visualize = 0 # Example: visualizing SCAN_0.ply from train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff7c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Define Paths ---\n",
    "global_labels_path = os.path.join(dataset_root_path, global_labels_file)\n",
    "\n",
    "if data_split == 'train':\n",
    "    map_file_path = os.path.join(dataset_root_path, train_map_file)\n",
    "    ply_folder_path = os.path.join(dataset_root_path, 'xtrain_kW4SLO1') # Assuming 'train' subdir for PLY files\n",
    "elif data_split == 'test':\n",
    "    map_file_path = os.path.join(dataset_root_path, test_map_file)\n",
    "    ply_folder_path = os.path.join(dataset_root_path, 'test') # Assuming 'test' subdir for PLY files\n",
    "else:\n",
    "    raise ValueError(\"data_split must be 'train' or 'test'\")\n",
    "\n",
    "ply_file_name = f'SCAN_{station_id_to_visualize}.ply'\n",
    "ply_file_path = os.path.join(ply_folder_path, ply_file_name)\n",
    "\n",
    "# Define class colors for visualization (you can expand this for all 10 classes)\n",
    "# These are just example colors. You can choose more distinct ones.\n",
    "# Make sure the index matches the label ID (e.g., colors[0] for label 0, colors[1] for label 1)\n",
    "# These are the 10 classes as per EDF dataset documentation (0-9)\n",
    "CLASS_COLORS = {\n",
    "    0: [0.5, 0.5, 0.5],  # Background (grey)\n",
    "    1: [1.0, 0.0, 0.0],  # Beams (red)\n",
    "    2: [0.0, 1.0, 0.0],  # Cabletrays (green)\n",
    "    3: [0.0, 0.0, 1.0],  # Civils (blue - for walls/floors)\n",
    "    4: [1.0, 1.0, 0.0],  # Gratings (yellow)\n",
    "    5: [1.0, 0.5, 0.0],  # Guardrails (orange)\n",
    "    6: [0.0, 1.0, 1.0],  # Hvac (cyan)\n",
    "    7: [0.5, 0.0, 0.5],  # Ladders (purple)\n",
    "    8: [1.0, 0.0, 1.0],  # Pipping (magenta - for pipes!)\n",
    "    9: [0.5, 0.5, 0.0],  # Supports (olive)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd53e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading global labels from: C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility\\ytrain_i9bpfD4.csv\n",
      "Successfully loaded 130661990 global labels.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. Load the Global Labels File ---\n",
    "print(f\"Loading global labels from: {global_labels_path}\")\n",
    "try:\n",
    "    # Assuming 'ID' column is index or just an identifier, and 'class' column holds the label\n",
    "    # The ID column might not be strictly necessary if indices directly map to point order.\n",
    "    # We'll just read the 'class' column as the labels array.\n",
    "    global_labels_df = pd.read_csv(global_labels_path)\n",
    "    # Ensure 'class' column exists and get its values\n",
    "    if 'class' not in global_labels_df.columns:\n",
    "        raise ValueError(\"Global labels CSV must contain a 'class' column.\")\n",
    "    all_labels = global_labels_df['class'].values\n",
    "    print(f\"Successfully loaded {len(all_labels)} global labels.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading global labels CSV: {e}\")\n",
    "    print(\"Please check 'global_labels_file' and its content.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc8a04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading map file from: C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility\\suppfiles_HtLAvex/ytrain_map_ind_station.csv\n",
      "Found mapping for Station 0: start=0, end=2368289\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2. Load the Map File for the chosen split ---\n",
    "print(f\"Loading map file from: {map_file_path}\")\n",
    "try:\n",
    "    map_df = pd.read_csv(map_file_path, header=None, names=['Station_index', 'index_start', 'index_end'])\n",
    "    # Find the row corresponding to our chosen station_id\n",
    "    station_info = map_df[map_df['Station_index'] == station_id_to_visualize]\n",
    "\n",
    "    if station_info.empty:\n",
    "        raise ValueError(f\"Station ID {station_id_to_visualize} not found in the map file: {map_file_path}\")\n",
    "\n",
    "    index_start = station_info['index_start'].iloc[0]\n",
    "    index_end = station_info['index_end'].iloc[0]\n",
    "    print(f\"Found mapping for Station {station_id_to_visualize}: start={index_start}, end={index_end}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading map file or finding station info: {e}\")\n",
    "    print(\"Please check 'map_file_path' and 'station_id_to_visualize'.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28aadd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2368290 labels for Station 0.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. Extract Labels for the Specific Station ---\n",
    "try:\n",
    "    labels_for_station = all_labels[index_start : index_end + 1] # +1 because end index is inclusive\n",
    "    print(f\"Extracted {len(labels_for_station)} labels for Station {station_id_to_visualize}.\")\n",
    "except IndexError as e:\n",
    "    print(f\"Index error when slicing global labels: {e}\")\n",
    "    print(\"This might indicate an issue with index_start/index_end or global_labels_file size.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b2714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c949b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to load PLY file: C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility\\xtrain_kW4SLO1\\SCAN_0.ply\n",
      "DEBUG: PLY file exists. Size: 36.14 MB\n",
      "Attempting to load PLY with 'plyfile' library for 'SCAN_0.ply' using custom element names...\n",
      "Successfully extracted 2368290 points from 'points' element.\n",
      "Warning: 'rgb' element found but missing 'r', 'g', or 'b' properties.\n",
      "Warning: 'intensity' element found but missing 'i' property.\n",
      "Successfully created Open3D PointCloud object with 2368290 points.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Load the Point Cloud (.ply file) for the specific station ---\n",
    "print(f\"\\nAttempting to load PLY file: {ply_file_path}\")\n",
    "\n",
    "# --- DEBUGGING CHECKS ---\n",
    "if not os.path.exists(ply_file_path):\n",
    "    print(f\"DEBUG: ERROR: PLY file DOES NOT EXIST at the specified path: {ply_file_path}\")\n",
    "    print(\"Please double-check your 'dataset_root_path', 'data_split' folder names (train/test), and 'station_id_to_visualize'.\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    file_size = os.path.getsize(ply_file_path) / (1024 * 1024) # Size in MB\n",
    "    print(f\"DEBUG: PLY file exists. Size: {file_size:.2f} MB\")\n",
    "    if file_size < 0.001: # Very small size, might be genuinely empty or just a header\n",
    "        print(\"DEBUG: WARNING: PLY file size is extremely small. It might be empty or corrupted.\")\n",
    "\n",
    "# --- MODIFIED PLY LOADING SECTION (using plyfile with correct element names) ---\n",
    "try:\n",
    "    print(f\"Attempting to load PLY with 'plyfile' library for '{ply_file_name}' using custom element names...\")\n",
    "    plydata = PlyData.read(ply_file_path)\n",
    "\n",
    "    # Extract points from the 'points' element\n",
    "    if 'points' in plydata:\n",
    "        points_element = plydata['points']\n",
    "        points = np.vstack([points_element['x'], points_element['y'], points_element['z']]).T\n",
    "        print(f\"Successfully extracted {len(points)} points from 'points' element.\")\n",
    "    else:\n",
    "        raise ValueError(\"PLY file does not contain a 'points' element as expected from header.\")\n",
    "\n",
    "    # Extract colors from the 'rgb' element\n",
    "    colors = None\n",
    "    if 'rgb' in plydata:\n",
    "        rgb_element = plydata['rgb']\n",
    "        # Assuming 'r', 'g', 'b' properties exist within 'rgb' element\n",
    "        if 'r' in rgb_element.properties and 'g' in rgb_element.properties and 'b' in rgb_element.properties:\n",
    "            colors = np.vstack([rgb_element['r'], rgb_element['g'], rgb_element['b']]).T\n",
    "            # Normalize colors to [0, 1] if they are 0-255 (uchar)\n",
    "            if colors.max() > 1.0:\n",
    "                colors = colors / 255.0\n",
    "            print(\"Successfully extracted RGB colors from 'rgb' element.\")\n",
    "        else:\n",
    "            print(\"Warning: 'rgb' element found but missing 'r', 'g', or 'b' properties.\")\n",
    "    else:\n",
    "        print(\"No 'rgb' element found in PLY file for colors.\")\n",
    "\n",
    "    # Optionally, extract intensity from the 'intensity' element\n",
    "    intensity = None\n",
    "    if 'intensity' in plydata:\n",
    "        intensity_element = plydata['intensity']\n",
    "        if 'i' in intensity_element.properties:\n",
    "            intensity = intensity_element['i']\n",
    "            print(f\"Successfully extracted {len(intensity)} intensity values from 'intensity' element.\")\n",
    "        else:\n",
    "            print(\"Warning: 'intensity' element found but missing 'i' property.\")\n",
    "    else:\n",
    "        print(\"No 'intensity' element found in PLY file.\")\n",
    "\n",
    "\n",
    "    # Create Open3D PointCloud object\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    if colors is not None:\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    # Note: Open3D does not have a direct 'intensity' property for visualization,\n",
    "    # but you can store it or use it for other processing.\n",
    "\n",
    "    if not pcd.has_points():\n",
    "        raise ValueError(\"PointCloud created from plyfile has no points after conversion.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to load PLY file using 'plyfile' library with custom elements: {e}\")\n",
    "    print(\"This suggests a deeper issue with the PLY file's structure or corruption, or an unexpected header format.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"Successfully created Open3D PointCloud object with {len(pcd.points)} points.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a15d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point cloud colored by semantic labels.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Verify Lengths and Prepare Colors for Visualization ---\n",
    "if len(pcd.points) != len(labels_for_station):\n",
    "    print(f\"\\nCRITICAL WARNING: Number of points ({len(pcd.points)}) in '{ply_file_name}' \"\n",
    "          f\"does NOT match number of labels ({len(labels_for_station)}) extracted via map file ({index_start}:{index_end+1}).\")\n",
    "    print(\"This is a common issue due to incorrect indexing, PLY file corruption, or mismatched data generation.\")\n",
    "    print(\"For visualization, truncating to the minimum length to avoid errors, but investigate this mismatch.\")\n",
    "    min_len = min(len(pcd.points), len(labels_for_station))\n",
    "    pcd.points = o3d.utility.Vector3dVector(np.asarray(pcd.points)[:min_len])\n",
    "    # Preserve original colors if they exist, otherwise set to dummy for slicing\n",
    "    # Use the colors loaded from PLY, or if not available, default to grey.\n",
    "    if pcd.has_colors():\n",
    "        pcd.colors = o3d.utility.Vector3dVector(np.asarray(pcd.colors)[:min_len])\n",
    "    else:\n",
    "        pcd.colors = o3d.utility.Vector3dVector(np.full((min_len, 3), 0.7)) # Grey if no colors from PLY\n",
    "    labels_for_station = labels_for_station[:min_len]\n",
    "    print(f\"Truncated to {min_len} points/labels for visualization.\")\n",
    "\n",
    "# Create an array to hold the colors based on labels\n",
    "colors_from_labels = np.zeros((len(labels_for_station), 3))\n",
    "for i, label_id in enumerate(labels_for_station):\n",
    "    label_id_int = int(label_id) # Ensure label_id is an integer for dictionary lookup\n",
    "    colors_from_labels[i] = CLASS_COLORS.get(label_id_int, [0.8, 0.8, 0.8]) # Default to light grey for unknown labels\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors_from_labels) # OVERWRITE with semantic colors\n",
    "print(\"Point cloud colored by semantic labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "827746a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizing Station 0 (train split). Close the visualization window to continue.\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n",
      "Visualization complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Visualize the Point Cloud ---\n",
    "print(f\"\\nVisualizing Station {station_id_to_visualize} ({data_split} split). Close the visualization window to continue.\")\n",
    "\n",
    "# Optional: Downsample for faster visualization if it's too dense\n",
    "# pcd_downsampled = pcd.voxel_down_sample(voxel_size=0.05) # Adjust voxel_size as needed\n",
    "# o3d.visualization.draw_geometries([pcd_downsampled])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "print(\"Visualization complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8507f56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initial Exploration Notes ---\n",
      "Number of points loaded for this station: 2368290\n",
      "Label distribution for this station:\n",
      "  Class Background (ID 0): 61829 points\n",
      "  Class Cabletrays (ID 2): 39641 points\n",
      "  Class Civils (ID 3): 400446 points\n",
      "  Class Guardrails (ID 5): 1403 points\n",
      "  Class Hvac (ID 6): 2766 points\n",
      "  Class Pipping (ID 8): 1705937 points\n",
      "  Class Supports (ID 9): 156268 points\n",
      "\n",
      "**Key things to observe during visualization (if successful):**\n",
      "- **Geometric Integrity:** Does the point cloud look complete and well-aligned? Are there obvious holes or misalignments?\n",
      "- **Label Consistency:** Do the colored regions truly correspond to the object types? For example, are all pipes (magenta) connected correctly, and are walls (blue) forming continuous surfaces?\n",
      "- **Boundaries:** How clear are the boundaries between different segmented objects? Are they sharp or blurry?\n",
      "- **Object Sizes & Density:** Observe the varying sizes of objects (e.g., large walls vs. thin pipes) and the point density on different surfaces.\n",
      "- **Occlusions:** Identify areas where objects are hidden behind others. This affects how well algorithms can segment them.\n",
      "- **Noise & Outliers:** Look for isolated points or small clusters far from the main structures, which might be sensor noise.\n",
      "- **Overall Complexity:** Get a feel for the complexity of the industrial scene and the challenges it might pose for segmentation.\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Initial Exploration Insights ---\n",
    "print(\"\\n--- Initial Exploration Notes ---\")\n",
    "print(f\"Number of points loaded for this station: {len(pcd.points)}\")\n",
    "unique_labels, counts = np.unique(labels_for_station, return_counts=True)\n",
    "print(\"Label distribution for this station:\")\n",
    "# Mapping label IDs to names for better readability\n",
    "label_names_map = {\n",
    "    0: \"Background\", 1: \"Beams\", 2: \"Cabletrays\", 3: \"Civils\", 4: \"Gratings\",\n",
    "    5: \"Guardrails\", 6: \"Hvac\", 7: \"Ladders\", 8: \"Pipping\", 9: \"Supports\"\n",
    "}\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    label_name = label_names_map.get(label, f\"Unknown ({label})\")\n",
    "    print(f\"  Class {label_name} (ID {label}): {count} points\")\n",
    "\n",
    "print(\"\\n**Key things to observe during visualization (if successful):**\")\n",
    "print(\"- **Geometric Integrity:** Does the point cloud look complete and well-aligned? Are there obvious holes or misalignments?\")\n",
    "print(\"- **Label Consistency:** Do the colored regions truly correspond to the object types? For example, are all pipes (magenta) connected correctly, and are walls (blue) forming continuous surfaces?\")\n",
    "print(\"- **Boundaries:** How clear are the boundaries between different segmented objects? Are they sharp or blurry?\")\n",
    "print(\"- **Object Sizes & Density:** Observe the varying sizes of objects (e.g., large walls vs. thin pipes) and the point density on different surfaces.\")\n",
    "print(\"- **Occlusions:** Identify areas where objects are hidden behind others. This affects how well algorithms can segment them.\")\n",
    "print(\"- **Noise & Outliers:** Look for isolated points or small clusters far from the main structures, which might be sensor noise.\")\n",
    "print(\"- **Overall Complexity:** Get a feel for the complexity of the industrial scene and the challenges it might pose for segmentation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83d7bd",
   "metadata": {},
   "source": [
    "### SCAN0\n",
    "\n",
    "\n",
    "Number of points loaded for this station: 2368290\n",
    "\n",
    "\n",
    "Class Background (ID 0): 61829 points :: GREY\n",
    "\n",
    "Class Beam (ID 1): 0 points :: Red\n",
    "\n",
    "Class Cabletrays (ID 2): 39641 points :: GREEN\n",
    "\n",
    "Class Civils (ID 3): 400446 points :: Blue(walls and floors)\n",
    "\n",
    "Class Gratings (ID 4): 0 points :: Yellow\n",
    "\n",
    "Class Guardrails (ID 5): 1403 points :: Orange\n",
    "\n",
    "Class Hvac (ID 6): 2766 points :: Cyan\n",
    "\n",
    "Class ladders (ID 7): 0 points :: purple\n",
    "\n",
    "Class Pipping (ID 8): 1705937 points :: Magenta for pipes\n",
    "\n",
    "Class Supports (ID 9): 156268 points :: olive\n",
    "\n",
    "\n",
    "    0: [0.5, 0.5, 0.5],  # Background (grey)\n",
    "    1: [1.0, 0.0, 0.0],  # Beams (red)\n",
    "    2: [0.0, 1.0, 0.0],  # Cabletrays (green)\n",
    "    3: [0.0, 0.0, 1.0],  # Civils (blue - for walls/floors)\n",
    "    4: [1.0, 1.0, 0.0],  # Gratings (yellow)\n",
    "    5: [1.0, 0.5, 0.0],  # Guardrails (orange)\n",
    "    6: [0.0, 1.0, 1.0],  # Hvac (cyan)\n",
    "    7: [0.5, 0.0, 0.5],  # Ladders (purple)\n",
    "    8: [1.0, 0.0, 1.0],  # Pipping (magenta - for pipes!)\n",
    "    9: [0.5, 0.5, 0.0],  # Supports (olive)\n",
    "\n",
    "Label distribution for this station:: This is critical!\n",
    "\n",
    "Look at the Class <Name> (ID <ID>): <Count> points for each unique label.\n",
    "\n",
    "Identify Class Imbalance: You will likely see that some classes (e.g., 'Civils', 'Pipping') have many more points than others (e.g., 'Ladders', 'Gratings'). This class imbalance is a common challenge in segmentation and will heavily influence your model training strategy (e.g., requiring weighted loss functions, oversampling rare classes).\n",
    "--> there is huge class imbalance like pipes are almost 1/2 of the total points whereas least are gaurdrails around 1k points\n",
    "\n",
    "Confirm all expected classes are present: Are all 10 classes potentially represented in this scan, or just a subset?\n",
    "\n",
    "--> not all classes have points there are there grating, beam and ladders which are not present\n",
    "\n",
    "\n",
    "Identify Objects by Color: Based on your CLASS_COLORS map, try to visually confirm what each color represents. For SCAN_0.ply, can you clearly distinguish:\n",
    "\n",
    "Magenta (Pipping): Do you see continuous pipe structures?\n",
    "--> they are dense but they are not continous, huge gap are there in between\n",
    "\n",
    "Blue (Civils): Are these mainly walls, floors, or large structural elements?\n",
    "--> Yes, similary, some are desne whereas some are sparse\n",
    "\n",
    "Green (Cabletrays): Can you pick out the cable trays?\n",
    "--> yes, they are less but can be identified and those are dense and get not continous in between \n",
    "Red (Beams): Are there structural beams?\n",
    "--> there is no points for that\n",
    "Other Colors: What about Gratings, Guardrails, HVAC, Ladders, Supports, Background?\n",
    "\n",
    "\n",
    "Boundary Observation: How clean are the boundaries between different colored segments? Are they sharp, or do they bleed into each other?\n",
    "--> there are some overlaps other vise its clean and sharp. magenta and blue are overlapping somewhere and are less overlapped. olive and green are bit overlapping but i guess it should get some overlapped\n",
    "Density & Completeness: Are there areas that are very dense or very sparse? Are there missing sections or large holes?\n",
    "--> There are dense but are missing section \n",
    "\n",
    "Noise/Outliers: Do you see any isolated points floating away from the main structures that appear to be noise?\n",
    "--> yes there are many sections which are far away and does not make any importance \n",
    "\n",
    "The visual is looked like it has been taken from one static Lidar sensor or scanner and then Point cloud was generated. beacause of that from one specific angle it has point cloud but looking from the opposite angle, the point cloud is missing but difficult to know exact which angle. for example a horizontal pipe has a dense( not so dense) point cloud but from opposite angle it has no points, looking like it has half pipe. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a30ae",
   "metadata": {},
   "source": [
    "## Checking for the points in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec8d24c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility/suppfiles_HtLAvex\\ytrain_map_ind_station.csv\n",
      "--- Scan Sizes Overview ---\n",
      "Total scans: 50\n",
      "Minimum points in a scan: 1612043\n",
      "Maximum points in a scan: 4132927\n",
      "Average points per scan: 2613239.80\n",
      "Median points per scan: 2656528.5\n",
      "\n",
      "--- Top 5 Smallest Scans ---\n",
      "   Station_index  index_start  index_end  point_count  split\n",
      "0             45    109487941  111099983      1612043  train\n",
      "1              4     10953766   12608556      1654791  train\n",
      "2             37     93562963   95226972      1664010  train\n",
      "3             42    104568399  106424116      1855718  train\n",
      "4             58    143275610  145192546      1916937  train\n",
      "\n",
      "--- Top 5 Largest Scans ---\n",
      "    Station_index  index_start  index_end  point_count  split\n",
      "45             64    160422335  163585348      3163014  train\n",
      "46              8     21074972   24391614      3316643  train\n",
      "47             12     32396605   35738625      3342021  train\n",
      "48              2      4856610    8309083      3452474  train\n",
      "49             61    150420389  154553315      4132927  train\n",
      "\n",
      "--- Example of 'Average' Sized Scans (around median) ---\n",
      "    Station_index  index_start  index_end  point_count  split\n",
      "18              1      2368290    4856609      2488320  train\n",
      "30             62    154553316  157370241      2816926  train\n",
      "33             18     49354416   52210232      2855817  train\n",
      "34             26     71466440   74324805      2858366  train\n",
      "35              6     15309272   18229356      2920085  train\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "Suppfiles_path = 'C:/RUTUL/GBC/WIP/Dataset/EDF Industrial Facility/suppfiles_HtLAvex' # <<< VERIFY THIS PATH\n",
    "\n",
    "train_map_file = 'ytrain_map_ind_station.csv'\n",
    "test_map_file = 'ytest_map_ind_station.csv'\n",
    "\n",
    "# Load train map\n",
    "train_map_path = os.path.join(Suppfiles_path, train_map_file)\n",
    "print(train_map_path)\n",
    "train_map_df = pd.read_csv(train_map_path, header=None, names=['Station_index', 'index_start', 'index_end'])\n",
    "train_map_df['point_count'] = train_map_df['index_end'] - train_map_df['index_start'] + 1\n",
    "train_map_df['split'] = 'train'\n",
    "\n",
    "# Load test map (if you have the test files available)\n",
    "\"\"\"test_map_path = os.path.join(Suppfiles_path, test_map_file)\n",
    "test_map_df = pd.read_csv(test_map_path, header=None, names=['Station_index', 'index_start', 'index_end'])\n",
    "test_map_df['point_count'] = test_map_df['index_end'] - test_map_df['index_start'] + 1\n",
    "test_map_df['split'] = 'test'\"\"\"\n",
    "\n",
    "# Combine and sort for easy viewing\n",
    "all_scans_df = train_map_df\n",
    "all_scans_df_sorted = all_scans_df.sort_values(by='point_count').reset_index(drop=True)\n",
    "\n",
    "print(\"--- Scan Sizes Overview ---\")\n",
    "print(f\"Total scans: {len(all_scans_df_sorted)}\")\n",
    "print(f\"Minimum points in a scan: {all_scans_df_sorted['point_count'].min()}\")\n",
    "print(f\"Maximum points in a scan: {all_scans_df_sorted['point_count'].max()}\")\n",
    "print(f\"Average points per scan: {all_scans_df_sorted['point_count'].mean():.2f}\")\n",
    "print(f\"Median points per scan: {all_scans_df_sorted['point_count'].median()}\")\n",
    "\n",
    "print(\"\\n--- Top 5 Smallest Scans ---\")\n",
    "print(all_scans_df_sorted.head(5))\n",
    "\n",
    "print(\"\\n--- Top 5 Largest Scans ---\")\n",
    "print(all_scans_df_sorted.tail(5))\n",
    "\n",
    "print(\"\\n--- Example of 'Average' Sized Scans (around median) ---\")\n",
    "median_count = all_scans_df_sorted['point_count'].median()\n",
    "print(all_scans_df_sorted[(all_scans_df_sorted['point_count'] >= median_count * 0.9) &\n",
    "                           (all_scans_df_sorted['point_count'] <= median_count * 1.1)].sample(n=min(5, len(all_scans_df_sorted))).sort_values(by='point_count'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WILP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
